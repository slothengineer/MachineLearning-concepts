{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8741f16-deb0-4e64-b3a5-1f8021459419",
   "metadata": {},
   "source": [
    "### What is Bayes' theorem and What is the formula for Bayes' theorem?\n",
    "\n",
    "Bayes' theorem, named after the 18th-century statistician and philosopher Thomas Bayes, is a fundamental concept in probability theory and statistics. It describes how to update our beliefs or probabilities about an event based on new evidence or information. In essence, it allows us to calculate the probability of an event occurring given our prior beliefs and new observed data.\n",
    "\n",
    "The theorem can be expressed mathematically as follows:\n",
    "\n",
    "          P(A|B) = (P(B|A).P(A))/P(B)\n",
    "\n",
    "Where:\n",
    "- P(A|B) is the conditional probability of event A occurring given that event B has occurred.\n",
    "- P(B|A) is the conditional probability of event B occurring given that event A has occurred.\n",
    "- P(A) is the prior probability of event A occurring (i.e., our initial belief in the probability of A).\n",
    "- P(B) is the prior probability of event B occurring (i.e., our initial belief in the probability of B).\n",
    "\n",
    "Bayes' theorem is particularly useful in situations where we have prior knowledge or beliefs about the likelihood of an event, and we want to update those beliefs based on new evidence. It is commonly used in various fields, including statistics, machine learning, and artificial intelligence, for tasks such as Bayesian inference, Bayesian networks, and Bayesian reasoning. Bayesian methods are valuable for making decisions and predictions in uncertain environments because they allow us to incorporate both prior knowledge and new data into our calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ca13b-f9f5-47a4-955e-488a210ae8c8",
   "metadata": {},
   "source": [
    "### How is Bayes' theorem used in practice?\n",
    "\n",
    "Bayes' theorem is used in various practical applications across different fields to make predictions, update beliefs, and perform statistical inference. Here are some common ways in which Bayes' theorem is applied in practice:\n",
    "\n",
    "1. **Medical Diagnosis**: Bayes' theorem is used in medical diagnosis to estimate the probability of a patient having a particular disease given certain symptoms, test results, and prior knowledge about the disease's prevalence in the population.\n",
    "\n",
    "2. **Spam Email Filtering**: Spam filters often use Bayesian classification to determine whether an incoming email is spam or not. They calculate the probability that an email is spam based on the words and phrases in the email and compare it to the probability of a legitimate email.\n",
    "\n",
    "3. **Machine Learning**: Bayesian methods, such as Naive Bayes classifiers, are used in machine learning for text classification, sentiment analysis, and recommendation systems. These algorithms calculate the probability of a data point belonging to a specific class based on its features.\n",
    "\n",
    "4. **Weather Forecasting**: Weather forecasting models often incorporate Bayesian techniques to update weather predictions based on real-time data and prior forecasts. This helps improve the accuracy of short-term and long-term weather predictions.\n",
    "\n",
    "5. **Stock Market Analysis**: Bayesian models can be used to estimate the probability distribution of future stock prices based on historical data and market conditions. This information can be valuable for investment decision-making.\n",
    "\n",
    "6. **Natural Language Processing**: Bayes' theorem is used in various natural language processing tasks, such as language modeling, speech recognition, and machine translation, to estimate the likelihood of different words or phrases appearing in a sequence of text.\n",
    "\n",
    "7. **A/B Testing**: In web and app development, A/B testing involves comparing two versions of a product to determine which one performs better. Bayes' theorem can be used to analyze the results of A/B tests and update beliefs about the effectiveness of different design or content changes.\n",
    "\n",
    "8. **Image and Pattern Recognition**: Bayesian models are applied in image processing and pattern recognition tasks to classify objects, recognize faces, and detect anomalies based on observed features and prior knowledge.\n",
    "\n",
    "9. **Predictive Modeling**: Bayes' theorem can be used to build predictive models in various fields, including finance, marketing, and healthcare. By continuously updating the model with new data, it can make more accurate predictions over time.\n",
    "\n",
    "10. **Bayesian Networks**: These graphical models represent complex probabilistic relationships among variables. They are used for tasks like risk assessment, decision support systems, and fault diagnosis in engineering and healthcare.\n",
    "\n",
    "In each of these applications, Bayes' theorem allows practitioners to combine prior knowledge or beliefs with new data to make informed decisions, predictions, or inferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f4888-85e3-4872-93d1-9168901aa653",
   "metadata": {},
   "source": [
    "### What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Bayes' theorem and conditional probability are closely related concepts in probability theory. In fact, Bayes' theorem can be thought of as a way to compute conditional probabilities in a particular manner. Here's how they are related:\n",
    "\n",
    "1. **Conditional Probability**:\n",
    "   Conditional probability is the probability of an event occurring given that another event has already occurred. It is denoted as P(A|B), which reads as \"the probability of event A given event B.\"\n",
    "\n",
    "2. **Bayes' Theorem**:\n",
    "   Bayes' theorem provides a way to compute conditional probabilities using the following formula:\n",
    "\n",
    "               P(A|B) = (P(B|A).P(A))/P(B)\n",
    "               \n",
    "\n",
    "   In this formula:\n",
    "   - P(A|B) is the conditional probability of event A given event B.\n",
    "   - P(B|A) is the conditional probability of event B given event A.\n",
    "   - P(A) is the prior probability of event A.\n",
    "   - P(B) is the prior probability of event B.\n",
    "\n",
    "The key relationship here is that Bayes' theorem allows us to calculate the conditional probability P(A|B) using information about P(B|A), P(A), and P(B). In other words, it lets us update our belief or knowledge about the probability of event A happening, given new evidence or information provided by event B.\n",
    "\n",
    "So, Bayes' theorem is a specific formula for calculating conditional probabilities, and it's a powerful tool for updating our beliefs or making predictions when we have prior knowledge and new data. It plays a crucial role in various fields, including statistics, machine learning, and decision-making, where understanding and calculating conditional probabilities are essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebe537-1cd9-49ce-bb08-db7e7290ef0d",
   "metadata": {},
   "source": [
    "### How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Choosing the appropriate type of Naive Bayes classifier for a given problem depends on the nature of the data and the assumptions that are reasonable for our specific application. There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here are some guidelines to help u decide which one to use:\n",
    "\n",
    "1. **Gaussian Naive Bayes**:\n",
    "   - **Continuous Data**: Use Gaussian Naive Bayes when our features are continuous (real-valued) and can be modeled as following a Gaussian (normal) distribution. It assumes that each class has normally distributed features.\n",
    "\n",
    "   - **Examples**: It's commonly used for problems like spam email classification (where features might include word frequencies) and medical diagnosis (where features might include patient age, blood pressure, etc.).\n",
    "\n",
    "2. **Multinomial Naive Bayes**:\n",
    "   - **Categorical Data**: Multinomial Naive Bayes is suitable for problems where features represent counts or frequencies of categorical data, such as word counts in text data. It assumes that features are generated from a multinomial distribution.\n",
    "\n",
    "   - **Examples**: Text classification tasks like sentiment analysis, document categorization, and spam detection are often addressed using Multinomial Naive Bayes.\n",
    "\n",
    "3. **Bernoulli Naive Bayes**:\n",
    "   - **Binary Data**: Use Bernoulli Naive Bayes when your data consists of binary features (i.e., features that are either present or absent, represented as 1 or 0). It assumes that features are generated from a Bernoulli distribution.\n",
    "\n",
    "   - **Examples**: Document classification where features represent the presence or absence of words in a document (binary bag-of-words), or image classification where features represent the presence or absence of certain image features.\n",
    "\n",
    "To make a decision about which type of Naive Bayes classifier to use, consider the following factors:\n",
    "\n",
    "- **Nature of Features**: Determine whether data consists of continuous, categorical, or binary features. Choose the classifier that aligns with the data type.\n",
    "\n",
    "- **Distribution Assumptions**: Consider whether the assumptions of the chosen Naive Bayes variant (e.g., Gaussian, Multinomial, Bernoulli) are reasonable for data. If the assumptions are met, the classifier is likely to perform well.\n",
    "\n",
    "- **Performance**: Experiment with different types of Naive Bayes classifiers on our specific problem and evaluate their performance using metrics like accuracy, precision, recall, and F1-score. Choose the one that performs best on our validation data.\n",
    "\n",
    "- **Data Size**: The size of dataset can also influence our choice. In cases of very small datasets, simpler models like Bernoulli Naive Bayes may be preferred to avoid overfitting.\n",
    "\n",
    "- **Preprocessing**: Consider how we preprocess data, such as handling missing values, feature scaling, or feature engineering. The choice of classifier may be influenced by your preprocessing steps."
   ]
  },
  {
   "attachments": {
    "14731e7d-3998-4de9-8854-da8b48e3a773.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAB1CAYAAABTeqhAAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\n"
    }
   },
   "cell_type": "markdown",
   "id": "9ead26bb-1144-4a49-a95f-6cf7241b10a5",
   "metadata": {},
   "source": [
    "### You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "![nb.png](attachment:14731e7d-3998-4de9-8854-da8b48e3a773.png)\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c094928-2900-4637-8eab-469d93f4ecad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define the prior probabilities for each class\n",
    "prior_prob_A = 0.5\n",
    "prior_prob_B = 0.5\n",
    "\n",
    "# define the conditional probabilities for each feature value given the class (on proivded data)\n",
    "cond_prob_X1_A = [3/10, 3/10, 4/10]\n",
    "cond_prob_X2_A = [4/10, 3/10, 3/10, 3/10]\n",
    "cond_prob_X1_B = [1/9, 2/9, 2/9]\n",
    "cond_prob_X2_B = [2/9, 2/9, 3/9, 3/9]\n",
    "\n",
    "# define the new instance with features X1 = 3 and X2 = 4\n",
    "new_instance_X1 = 3\n",
    "new_instance_X2 = 4\n",
    "\n",
    "# calculate the likelihood for each class\n",
    "likelihood_A = cond_prob_X1_A[new_instance_X1-1] * cond_prob_X2_A[new_instance_X2-1]\n",
    "likelihood_B = cond_prob_X1_B[new_instance_X1-1] * cond_prob_X2_B[new_instance_X2-1]\n",
    "\n",
    "# calculate unnormalized posterior probabilities\n",
    "unnormalized_posterior_A = prior_prob_A * likelihood_A\n",
    "unnormalized_posterior_B = prior_prob_B * likelihood_B\n",
    "\n",
    "# normalize the posterior probabilities\n",
    "normalized_posterior_A = unnormalized_posterior_A / (unnormalized_posterior_A + unnormalized_posterior_B)\n",
    "normalized_posterior_B = unnormalized_posterior_B / (unnormalized_posterior_A + unnormalized_posterior_B)\n",
    "\n",
    "# compare the normalized probabilities and make the prediction\n",
    "if normalized_posterior_A > normalized_posterior_B:\n",
    "    predicted_class = 'A'\n",
    "else:\n",
    "    predicted_class = 'B'\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdecb8cc-6fa5-4ca9-bb25-a717a6a23d1f",
   "metadata": {},
   "source": [
    "lets check manually:\n",
    "    \n",
    "To predict the class of a new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we will calculate the conditional probabilities of the instance belonging to each class (A and B) and then choose the class with the higher probability.\n",
    "\n",
    "1. Calculate the prior probabilities of each class. Since the problem states \"equal prior probabilities for each class,\" both Class A and Class B have a prior probability of 0.5.\n",
    "\n",
    "2. Calculate the conditional probabilities for each feature value given the class. We'll calculate these probabilities for each feature separately and then multiply them together for each class.\n",
    "\n",
    "   For Class A:\n",
    "   - P(X1=3 | A) = 4/10\n",
    "   - P(X2=4 | A) = 3/10\n",
    "\n",
    "   For Class B:\n",
    "   - P(X1=3 | B) = 1/9\n",
    "   - P(X2=4 | B) = 3/9\n",
    "\n",
    "3. Calculate the likelihood for each class. This is the product of the conditional probabilities for each feature given the class.\n",
    "\n",
    "   For Class A:\n",
    "   - P(X1=3, X2=4 | A) = P(X1=3 | A) . P(X2=4 | A) = 4/10 . 3/10 = 12/100\n",
    "\n",
    "   For Class B:\n",
    "   - P(X1=3, X2=4 | B) = P(X1=3 | B) . P(X2=4 | B) = 1/9 . 3/9 = 3/81\n",
    "\n",
    "4. Multiply the prior probability by the likelihood for each class to calculate the unnormalized posterior probabilities.\n",
    "\n",
    "   For Class A:\n",
    "   - P(A) . P(X1=3, X2=4 | A) = 0.5 * 12/100 = 6/100\n",
    "\n",
    "   For Class B:\n",
    "   - P(B) . P(X1=3, X2=4 | B) = 0.5 * 3/81 = 3/162\n",
    "\n",
    "5. Normalize the posterior probabilities by dividing by the sum of the unnormalized probabilities.\n",
    "\n",
    "   For Class A:\n",
    "   - Normalized (P(A | X1=3, X2=4)) = (6/100)/(6/100 + 3/162) ≈ 0.974\n",
    "\n",
    "   For Class B:\n",
    "   - Normalized (P(B | X1=3, X2=4)) = (3/162)/(6/100 + 3/162) ≈ 0.026\n",
    "\n",
    "6. Compare the normalized probabilities. The class with the highest probability is the predicted class.\n",
    "\n",
    "In this case, the normalized probability for Class A is much higher (approximately 0.974) than for Class B (approximately 0.026). Therefore, according to the Naive Bayes classifier, the new instance with features X1 = 3 and X2 = 4 is predicted to belong to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c01992-df90-40df-8bc8-7c80964688d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
